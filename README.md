# Pr√°ctica M√≥dulo Big Data Arquitectura
### Bootcamp Big Data, Machine Learning & IA_Keepcoding
---

Este repositorio contiene el desarrollo de un ejercicio pr√°ctico en el que conectamos **Hadoop** con **ElasticSearch**, estableciendo una integraci√≥n entre Hive y un √≠ndice de **ElasticSearch**, desarrollando as√≠ competencias clave en arquitectura Big Data y an√°lisis de datos en tiempo real. Para todo esto se ha utilizado **Google Cloud Platform** como entorno principal.

---

## üéØ Objetivos de la Pr√°ctica

El objetivo de esta pr√°ctica es entender y aplicar los fundamentos de la integraci√≥n entre sistemas de Big Data y motores de b√∫squeda, espec√≠ficamente mediante la conexi√≥n de Hadoop con **ElasticSearch**. A trav√©s de este ejercicio se configura un entorno completo, desde la creaci√≥n de clusters y servidores hasta la realizaci√≥n de consultas y la visualizaci√≥n de datos. 

---

## üß© Desarrollo de la Pr√°ctica 

**PARTE 1: CONFIGURACI√ìN ES-HADOOP**

En esta secci√≥n, configuramos la integraci√≥n entre **ElasticSearch**  y **Hadoop**, utilizando las siguientes herramientas:

* Cluster standalone o est√°ndar en Dataproc.

* ELK Stack: ElasticSearch, Logstash y Kibana.

Pasos principales:

1. Crear un cluster **Hadoop**.

2. Descargar y subir los JARs necesarios al cluster:

Los jars de configuraci√≥n de elastichsearch-hadoop y commons-httpclient aqu√≠ üëâüèª : [elasticsearch-hadoop](https://artifacts.elastic.co/downloads/elasticsearch-hadoop/elasticsearch-hadoop-8.14.1.zip), [commons-httpclient]( https://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar).

Creamos un nuevo bucket para nuestro ES-Hadoop y subimos ambos jar a nuestro bucket en google storage. 

3. Descarga de los jar desde el bucket al filesystem del cluster: desde la consola SSH del nodo maestro del cluster los subimos con los siguientes comandos:

```
gsutil cp gs://bucket-para-elastic/jars/elastic/elasticsearch-hadoop-8.14.1.jar .

gsutil cp gs://bucket-para-elastic/jars/elastic/commons-httpclient-3.1.jar .
```
  

**PARTE 2: CONFIGURACI√ìN DEL SERVIDOR ELASTICSEARCH**

Se implementa y configura un servidor **ElasticSearch** con los siguientes pasos:

1. Crear una nueva m√°quina virtual para **ElasticSearch**.
   
2. Descargar e instalar **ElasticSearch** y **Kibana**:

Primero, instalamos wget, que nos permitir√° descargar cualquier instalable (lanzaremos los comandos como administrador):

```
sudo apt install wget
```

Descargamos las ultimas versiones de elastic y kibana:

```
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.14.1-amd64.deb
wget https://artifacts.elastic.co/downloads/kibana/kibana-8.14.1-amd64.deb
```

Procedemos a instalar y configurar ambos:

```
sudo dpkg -i elasticsearch-8.14.1-amd64.deb
sudo dpkg -i kibana-8.14.1-amd64.deb
```

Para versiones anteriores a *Elasticsearch 8* a√±adimos lo siguiente para que no acepte solo conexiones locales, sino desde cualquier IP:

```
sudo sed -i -e '$ahttp.host: 0.0.0.0' /etc/elasticsearch/elasticsearch.yml
sudo cat /etc/elasticsearch/elasticsearch.yml
```

```
sudo nano /etc/elasticsearch/elasticsearch.yml
```

Indicamos "false" en las siguientes variables:

*xpack.security.enabled: false*

*xpack.security.http.ssl:enabled: false*


Para configurar **Kibana**, independientemente de la versi√≥n:

```
sudo sed -i -e '$aserver.host: 0.0.0.0' /etc/kibana/kibana.yml
sudo cat /etc/kibana/kibana.yml
```

Finalmente, arrancamos (reiniciamos) tanto **ElasticSearch** como **Kibana**:

```
sudo service elasticsearch restart
sudo service kibana restart
```

3. Configurar las reglas de firewall para abrir los puertos 9200 y 5601.

4. Comprobar la conexi√≥n entre el cluster **Hadoop** y **ElasticSearch**:

```
curl -X GET "http://IP-MAQUINA-ESLASTIC:9200"
```


**PARTE 3: CONEXI√ìN DEL CLUSTER HADOOP CON ELASTICSEARCH**

Configuramos Hive para integrarse con ElasticSearch:

1. Modificar el archivo hive-site.xml con las propiedades necesarias y cargar los JARs en **Hive**:

```
sudo sed -i '$d' /etc/hive/conf.dist/hive-site.xml

sudo sed -i '$a \  <property>\n    <name>es.nodes</name>\n    <value>IP-ELASTIC</value>\n  </property>\n' /etc/hive/conf.dist/hive-site.xml

sudo sed -i '$a \  <property>\n    <name>es.port</name>\n    <value>9200</value>\n  </property>\n' /etc/hive/conf.dist/hive-site.xml

sudo sed -i '$a \  <property>\n    <name>es.nodes.wan.only</name>\n    <value>true</value>\n  </property>\n' /etc/hive/conf.dist/hive-site.xml

sudo sed -i '$a \  <property>\n    <name>hive.aux.jars.path</name>\n   <value>/usr/lib/hive/lib/elasticsearch-hadoop-8.14.1.jar,/usr/lib/hive/lib/commons-httpclient-3.1.jar</value>\n  </property>\n</configuration>' /etc/hive/conf.dist/hive-site.xml

sudo cp elasticsearch-hadoop-8.14.1.jar /usr/lib/hive/lib/
sudo cp commons-httpclient-3.1.jar /usr/lib/hive/lib/

```

2. Reiniciar **Hive** desde SSH del nodo maestro del cluster de Hadoop para que se apliquen los cambios.


**PARTE 4: CONECTAR DATOS**

Desde el server ElasticSearch:

1. Crear un √≠ndice llamado *alumnos*:

```
curl -X POST "localhost:9200/alumnos/_doc/6" -H 'Content-Type: application/json' -d'
{
  "title": "New Document",
  "content": "This is a new document for the master class",
  "tag": ["general", "testing"]
}
'
```

2. Insertar documentos en el √≠ndex *alumnos* desde **Hadoop** usando comandos CURL:

```
curl -X POST "IP-SERVER-ELASTICSEARCH:9200/_bulk" -H 'Content-Type: application/json' -d'
{ "index": { "_index": "alumnos", "_id": "3" } }
{ "id": 3, "name": "Carlos", "last_name": "Gonz√°lez" }
{ "index": { "_index": "alumnos", "_id": "4" } }
{ "id": 4, "name": "Mar√≠a", "last_name": "L√≥pez" }
{ "index": { "_index": "alumnos", "_id": "5" } }
{ "id": 5, "name": "Luis", "last_name": "Mart√≠nez" }
{ "index": { "_index": "alumnos", "_id": "7" } }
{ "id": 7, "name": "Sof√≠a", "last_name": "Ram√≠rez" }
{ "index": { "_index": "alumnos", "_id": "8" } }
{ "id": 8, "name": "Pedro", "last_name": "Hern√°ndez" }
'
```

3. Realizar una consulta para ver los datos insertados:

```
curl -X GET "http://IP-SERVER-ELASTIC:9200/alumnos/_search?pretty"
```


**PARTE 5: Visualizaci√≥n con **Kibana****

Creamos un sencillo dashboard con **Kibana** para visualizar datos del index *alumons*.

Para ello desde nuestro navegador, entramos en: **http://IP_ELASTIC_SERVER:5601**, y en **Analitycs** hacemos click en **Dashboards**. A continuaci√≥n, hacemos click en **Create Dataview**, dende selecionamos el index *alumnos*. 

Por √∫ltimo, en **Create Dashboard** y **Create Visualization** encontramos una variedad de gr√°ficos que podemos elegir para la visulizaci√≥n que mejor se ajuste a las caracter√≠sticas de los datos. En este caso he elegido un gr√°fico de anillo.


El documento PDF con las capturas de las diferentes partes de la pr√°ctica se pueden ver en este enlace üëâüèª: [PraÃÅctica ElacticSearch_Hadoop.pdf](https://github.com/Leticia2512/Practica-BigData_Architecture/blob/main/Pra%CC%81ctica%20ElacticSearch_Hadoop.pdf).

___


## üõ†Ô∏è Lenguajes y Herramientas Utilizadas

- **Hadoop**: Framework empleado para el procesamiento y almacenamiento distribuido de grandes vol√∫menes de datos.

- **Hive**: Herramienta utilizada para la consulta y an√°lisis de datos estructurados en el entorno de Hadoop.

- **ElasticSearch**: Motor de b√∫squeda y an√°lisis utilizado para crear √≠ndices y realizar b√∫squedas en grandes cantidades de datos.

- **Kibana**: Plataforma de visualizaci√≥n empleada para analizar los datos almacenados en ElasticSearch.

- **Google Cloud Platform (GCP)**: Entorno en la nube para la implementaci√≥n y gesti√≥n de las herramientas del proyecto.

- **Python**: Lenguaje de programaci√≥n empleado para la integraci√≥n y scripts complementarios.

___


## üîó Recursos √∫tiles 

- [Documentaci√≥n ElasticSearch-Hadoop](https://www.elastic.co/guide/en/elasticsearch/hadoop/index.html)

- [Logstash](https://www.elastic.co/logstash)

- [Kibana](https://www.elastic.co/kibana)

